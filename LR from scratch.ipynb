{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MVtgxmsddqop"
   },
   "source": [
    "# Linear Regression using Gradient Descent from scratch\n",
    "##### By: Ravikumar Patel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "atYvlhjBzrHR",
    "outputId": "664332ee-8506-493f-a8f0-548839e29f0b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class Linear_Regression:\n",
    "    \n",
    "    def __init__(self, learning_rate_b=0.1, learning_rate_w=0.1, max_iter=10000):\n",
    "      self.learning_rate_b=learning_rate_b\n",
    "      self.learning_rate_w=learning_rate_w\n",
    "      self.max_iter=max_iter\n",
    "      self.w = [0]\n",
    "    \n",
    "    def get_weights(self):\n",
    "      return self.w\n",
    "    \n",
    "    def train (self, data, target, initialization = None):\n",
    "\n",
    "      if type(data) != np.ndarray:\n",
    "        data = np.array(data)\n",
    "\n",
    "      if np.isnan(data).any() == True:\n",
    "        print(\"Error: The data contains null/NaN value/s.\")\n",
    "        return\n",
    "\n",
    "      # combining initial values\n",
    "      features = data.shape[1]+1\n",
    "      \n",
    "      if initialization != None and len(initialization) != features:\n",
    "        print(\"Error: initialization has wrong number of values!\")\n",
    "        return\n",
    "\n",
    "      if initialization == None:\n",
    "        self.w = np.array([[0]]*features)\n",
    "      else:\n",
    "        self.w = np.array([[x] for x in initialization])\n",
    "\n",
    "      n = target.size\n",
    "    \n",
    "      target = target.reshape((n,1))\n",
    "      \n",
    "      # creating a column of ones\n",
    "      one_vector = np.ones((n,1),dtype=int)\n",
    "\n",
    "      # adding a column of ones\n",
    "      data = np.hstack((one_vector, data))\n",
    "\n",
    "      # combining learning rates\n",
    "      lst_lr = [[self.learning_rate_b]]\n",
    "      lst_lr.extend([[self.learning_rate_w]] * (features-1))\n",
    "      learning_rates = np.array(lst_lr)\n",
    "      \n",
    "      for i in range(self.max_iter+1):\n",
    "\n",
    "        # prediting the target value\n",
    "        y = np.dot(data, self.w)\n",
    "\n",
    "        # finding differnece in the predicted value and target value\n",
    "        residuals = y - target\n",
    "        \n",
    "        # finding the cost\n",
    "        cost = np.mean((residuals ** 2))\n",
    "\n",
    "        # updating the weights for features and bias\n",
    "        self.w = self.w - ((2*learning_rates / n) * np.dot(data.T, residuals))\n",
    "    \n",
    "    def predict(self, test):\n",
    "      n = len(test)\n",
    "\n",
    "      # creating a column of ones\n",
    "      one_vector = np.ones((n,1),dtype=int)\n",
    "\n",
    "      # adding a column of ones\n",
    "      test = np.hstack((one_vector, test))\n",
    "    \n",
    "      return np.dot(test, self.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# reading data from the file\n",
    "X, y, real_coef = make_regression(n_samples=500, n_features=2, noise=0.3, random_state=10, coef=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "lr = Linear_Regression()\n",
    "\n",
    "lr.train(X_train, y_train)\n",
    "\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "\n",
    "y_pred_coef = lr.get_weights()[1:]\n",
    "\n",
    "print( \"Model's RSE: {:.8f}\".format(np.sqrt(mean_squared_error(y_test, y_pred_lr))))\n",
    "\n",
    "print(\"Absolute Difference between real coef and predicted: {:.3f}\".format(mean_absolute_error(real_coef,y_pred_coef)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "https://en.wikipedia.org/wiki/Linear_regression\n",
    "\n",
    "https://machinelearningmastery.com/linear-regression-for-machine-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "is932NVpd6-q",
    "c0oZgcAbePMz",
    "Erk3tNgbexJC",
    "s2zjh9LdfaUa",
    "iW_MM80GK9y1",
    "A9Hm_ks9gGGD",
    "Rg2qu0hiiI0o",
    "L8vz0mhYio9o",
    "YyeGC1g0isZX",
    "TPwLWrjZi86B",
    "5GiuIFwCjCj3",
    "n5uSTgncXEcH",
    "1oNIqH-vjdPr",
    "r2LbDdpbjh4l"
   ],
   "name": "Patel-Ravikumar-Assignment-1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
